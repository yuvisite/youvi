import json
import subprocess
import sys
import tempfile
import os
import re
import random
from time import time

def parse_timestamp(ts: str) -> float:
    parts = ts.split(":")
    try:
        parts = [int(p) for p in parts]
    except ValueError:
        return None
    if len(parts) == 3:
        h, m, s = parts
    elif len(parts) == 2:
        h, m, s = 0, parts[0], parts[1]
    elif len(parts) == 1:
        h, m, s = 0, 0, parts[0]
    else:
        return None
    return h * 3600 + m * 60 + s


def main():
    if len(sys.argv) < 2:
        print("Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ: python yt_comments_to_danmaku.py <ÑÑÑ‹Ð»ÐºÐ°_Ð½Ð°_Ð²Ð¸Ð´ÐµÐ¾> [Ð¾Ð¿Ñ†Ð¸Ð¸_yt-dlp]")
        sys.exit(1)

    url = sys.argv[1]
    extra_args = sys.argv[2:]
    tmpdir = tempfile.mkdtemp()

    print("ðŸ“¥ Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ñ‡ÐµÑ€ÐµÐ· yt-dlp...")
    cmd = [
        "yt-dlp",
        "--write-comments",
        "--skip-download",
        "--no-warnings",
        "--extractor-args", "youtube:max_comments=10000,10000,0,0",
        "-o", os.path.join(tmpdir, "%(id)s.%(ext)s"),
        *extra_args,
        url
    ]
    subprocess.run(cmd, check=True)

    info_file = None
    for f in os.listdir(tmpdir):
        if f.endswith(".info.json"):
            info_file = os.path.join(tmpdir, f)
            break

    if not info_file:
        print("âŒ yt-dlp Ð½Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ð» Ñ„Ð°Ð¹Ð» ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² (Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ñƒ Ð²Ð¸Ð´ÐµÐ¾ Ð½ÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ð½Ð¸Ð¼).")
        sys.exit(1)

    with open(info_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    comments = data.get("comments", [])
    print(f"ðŸ” Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²: {len(comments)}")
    
    if len(comments) > 0:
        for i, c in enumerate(comments[:5]):
            print(f"  [{i}] {c.get('text', '')[:80]}")

    danmaku = []
    now_ms = int(time() * 1000)

    colors = ["#ffffff", "#ff0000", "#00ff00", "#0000ff", "#ffff00", "#ff69b4"]
    
    time_pattern = re.compile(r"\b(\d{1,2}:\d{2}(?::\d{2})?)\b")

    for i, c in enumerate(comments):
        text = c.get("text", "")
        matches = time_pattern.findall(text)
        if not matches:
            continue

        ts = parse_timestamp(matches[0])
        if ts is None:
            continue

        clean_text = time_pattern.sub("", text).strip()

        color = random.choice(colors) if random.random() < 0.2 else "#ffffff"

        danmaku.append({
            "id": str(now_ms + i),
            "text": clean_text,
            "time": ts,
            "color": color,
            "size": "normal",
            "position": "scroll",
            "created": now_ms + i,
            "shown": False
        })

    print(f"âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ñ Ñ‚Ð°Ð¹Ð¼ÐºÐ¾Ð´Ð°Ð¼Ð¸: {len(danmaku)}")

    if not danmaku:
        print("âš ï¸ ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ñ Ñ‚Ð°Ð¹Ð¼ÐºÐ¾Ð´Ð°Ð¼Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹.")
        sys.exit(0)

    video_id = data.get("id", "comments")
    out_file = f"{video_id}_danmaku.json"

    with open(out_file, "w", encoding="utf-8") as f:
        json.dump(danmaku, f, ensure_ascii=False, indent=2)

    print(f"âœ… ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ñ Ñ‚Ð°Ð¹Ð¼ÐºÐ¾Ð´Ð°Ð¼Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {out_file}")

if __name__ == "__main__":
    main()